# Retriever Configuration (v7.0 Elastic Retriever)
# è¿™ä¸ªæ–‡ä»¶ç°åœ¨ç”Ÿæˆé€šç”¨çš„é€»è¾‘ï¼Œå…·ä½“çš„æ£€ç´¢ç­–ç•¥ç”± rag_config.json è¿è¡Œæ—¶å†³å®š

def get_retriever():
    """å·¥å‚å‡½æ•°ï¼šæ ¹æ®å½“å‰é…ç½®åŠ¨æ€æ„å»ºæ£€ç´¢å™¨ç®¡é“ (Elastic Pipeline)"""
    # 1. åŠ¨æ€åŠ è½½é…ç½®
    config = CONFIG_LOADER.load_rag_config()
    
    k = config.get("k_retrieval", 4)
    chunk_size = config.get("chunk_size", 1000) # Used by splitter if re-splitting needed
    
    print(f"ğŸ” [RAG] æ„å»ºæ£€ç´¢å™¨: k={k}, Hybrid={config.get('enable_hybrid_search')}, Rerank={config.get('reranker_enabled')}")
    
    # 2. åŸºç¡€å‘é‡æ£€ç´¢ (Vector Store)
    # ------------------------------------------------
    search_type = config.get("search_type", "similarity")
    search_kwargs = {"k": k}
    
    if search_type == "similarity_score_threshold":
        search_kwargs["score_threshold"] = config.get("score_threshold", 0.5)
    elif search_type == "mmr":
        search_kwargs["fetch_k"] = config.get("fetch_k", 20)
        search_kwargs["lambda_mult"] = config.get("lambda_mult", 0.5)
        
    base_retriever = vectorstore.as_retriever(
        search_type=search_type,
        search_kwargs=search_kwargs
    )
    
    # 3. æ··åˆæ£€ç´¢å±‚ (Hybrid Search Layer)
    # ------------------------------------------------
    # åªè¦ config å¼€å¯ï¼Œä¸”ä¾èµ–å­˜åœ¨ï¼Œå°±è‡ªåŠ¨æ¿€æ´»
    if config.get("enable_hybrid_search", False):
        try:
            from langchain_community.retrievers import BM25Retriever
            from langchain.retrievers import EnsembleRetriever
            
            # ä½¿ç”¨å…¨å±€ splits (å‡è®¾åœ¨ rag_document_loader ä¸­å®šä¹‰)
            # å¦‚æœæ˜¯è¿è¡Œæ—¶åŠ è½½ï¼Œå¯èƒ½éœ€è¦é‡æ–°è¯»å– documents (è¿™é‡Œå‡è®¾ loaded_docs/splits å­˜åœ¨ä¸”æŒä¹…åŒ–ä¸å¤ªç°å®ï¼Œ
            # å®é™…ä¸Š BM25 éœ€è¦é‡æ–°æ„å»ºç´¢å¼•ã€‚
            # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬å‡è®¾ `splits` å˜é‡åœ¨ agent.py ä¸Šä¸‹æ–‡ä¸­å¯ç”¨ã€‚
            # æ³¨æ„: å¤§é‡æ–‡æ¡£ rebuild BM25 ä¼šå¾ˆæ…¢ï¼Œå»ºè®®åªåœ¨å°æ–‡æ¡£é›†ä½¿ç”¨ï¼Œæˆ–ä½¿ç”¨æŒä¹…åŒ– BM25 (è¿›é˜¶)
            if 'splits' in globals() and splits:
                bm25 = BM25Retriever.from_documents(splits)
                bm25.k = k
                
                base_retriever = EnsembleRetriever(
                    retrievers=[base_retriever, bm25],
                    weights=[
                        config.get("vector_weight", 0.5), 
                        config.get("bm25_weight", 0.5)
                    ]
                )
                print("âœ… [RAG] æ··åˆæ£€ç´¢å·²æ¿€æ´» (Vector + BM25)")
            else:
                print("âš ï¸ [RAG] æ— æ³•æ¿€æ´»æ··åˆæ£€ç´¢: æœªæ‰¾åˆ°æ–‡æ¡£åˆ‡ç‰‡ (splits)")
        except ImportError:
            print("âš ï¸ [RAG] æœªå®‰è£… rank_bm25ï¼Œé™çº§ä¸ºçº¯å‘é‡æ£€ç´¢")
        except Exception as e:
            print(f"âš ï¸ [RAG] æ··åˆæ£€ç´¢åˆå§‹åŒ–å¤±è´¥: {e}")

    # 4. é‡æ’åºå±‚ (Reranking Layer)
    # ------------------------------------------------
    if config.get("reranker_enabled", False):
        try:
            # ä¼˜å…ˆä½¿ç”¨ Flashrank (è½»é‡çº§)
            from langchain.retrievers import ContextualCompressionRetriever
            from langchain.retrievers.document_compressors import FlashrankRerank
            
            # [v7.2 Update] Noise Filter
            # We treat 'k' as the candidate pool. We only keep the Top 10 most relevant.
            final_top_n = min(k, 10)
            
            compressor = FlashrankRerank(
                top_n=final_top_n
            )
            
            final_retriever = ContextualCompressionRetriever(
                base_compressor=compressor,
                base_retriever=base_retriever
            )
            print("âœ… [RAG] é‡æ’åºå·²æ¿€æ´» (Flashrank)")
            return final_retriever
            
        except ImportError:
             print("âš ï¸ [RAG] æœªå®‰è£… flashrankï¼Œè·³è¿‡é‡æ’åº")
        except Exception as e:
             print(f"âš ï¸ [RAG] é‡æ’åºåˆå§‹åŒ–å¤±è´¥: {e}")
    
    return base_retriever

# åˆå§‹åŒ–å…¨å±€ retriever
retriever = get_retriever()
